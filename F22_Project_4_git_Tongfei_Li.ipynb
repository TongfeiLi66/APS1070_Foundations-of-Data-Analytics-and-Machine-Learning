{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTpnyUEJrAjE"
   },
   "source": [
    "# Project 4, Git Practice, APS1070 Fall 2022\n",
    "#### **Linear Regression -  14 points**\n",
    "**Deadline: Dec 1st, 21:00**\n",
    "\n",
    "**Academic Integrity**\n",
    "\n",
    "This project is individual - it is to be completed on your own. If you have questions, please post your query in the APS1070 Piazza Q&A forums (the answer might be useful to others!).\n",
    "\n",
    "Do not share your code with others, or post your work online. Do not submit code that you have not written yourself. Students suspected of plagiarism on a project, midterm or exam will be referred to the department for formal discipline for breaches of the Student Code of Conduct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUdJ6xw3rJIG"
   },
   "source": [
    "Please fill out the following:\n",
    "\n",
    "\n",
    "*   Your **name**: Tongfei Li\n",
    "*   Your **student number**: 1004759460\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sy0M4UZZNEk2"
   },
   "source": [
    "## Gradient Descent with Additional Features and Regularization [2 marks + 1 mark Git submission]\n",
    "\n",
    "We'll apply linear regresssion to a toy dataset (`LR_data.csv`), with 10 features `x1`-`x10` and a \"measurement\" `y`. We'll take a few shortcuts by using built-in sklearn functions.\n",
    "\n",
    "1. Data Preparation **[0.5]**\n",
    "  * Print the dataset, and create Numpy arrays with inputs (X) and outputs (y). \n",
    "  * Split the dataset into training and validation sets (80% training, 20% validation). When splitting, set `random_state=1`.\n",
    "\n",
    "2. Linear Regression **[0.5]**\n",
    "  * Standardize the data using StandardScaler from sklearn.\n",
    "  * Use the `sklearn.linear_model.LinearRegression` function [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) to perform linear regression.\n",
    "  * Print the RMSE for training and validation data.\n",
    "\n",
    "3. Linear Regression with Additional Features **[0.5]**\n",
    "  * Let's add more features to our dataset (degree 8) using `sklearn.preprocessing.PolynomialFeatures` [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html). You'll want to create the additional features first, then perform standardization (start from non-standardized data).\n",
    "  * Again, use `sklearn.linear_model.LinearRegression` to perform linear regression.\n",
    "  * Print the RMSE for training and validation data.\n",
    "\n",
    "4. Linear Regression with Additional Features and Regularization **[0.5]**\n",
    "  * Let's switch models, and instead use the `sklearn.linear_model.Ridge` function [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) to perform linear regression with regularization. Apply the model to the processed data (additional, standardized) you used in 3 above. Use a `FOR` loop to run `sklearn.linear_model.Ridge` with different `alpha` values. Specifically, sweep `alpha` from 1E-2 to 1E10 (each step is an order of magnitude jump)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6ZKR243TOERR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"https://raw.githubusercontent.com/aps1070-2019/datasets/master/LR_data.csv\" , skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GPh_YldR21q0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkOmHFjS0peT"
   },
   "source": [
    "### 1. Data Preparation **[0.5]**\n",
    "\n",
    "  * Print the dataset, and create Numpy arrays with inputs (X) and outputs (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "GpTAcqKa0hWN",
    "outputId": "0eafc7f8-1108-46be-909f-5d43182b949f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.454481</td>\n",
       "      <td>4.940543</td>\n",
       "      <td>7.116015</td>\n",
       "      <td>3.805131</td>\n",
       "      <td>4.105432</td>\n",
       "      <td>1.832290</td>\n",
       "      <td>5.211909</td>\n",
       "      <td>5.088293</td>\n",
       "      <td>3.841250</td>\n",
       "      <td>6.121133</td>\n",
       "      <td>6.575066e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.907182</td>\n",
       "      <td>1.653654</td>\n",
       "      <td>7.339445</td>\n",
       "      <td>9.065282</td>\n",
       "      <td>7.169233</td>\n",
       "      <td>2.354136</td>\n",
       "      <td>2.893005</td>\n",
       "      <td>8.720131</td>\n",
       "      <td>8.646473</td>\n",
       "      <td>3.806860</td>\n",
       "      <td>8.419881e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.842804</td>\n",
       "      <td>1.183878</td>\n",
       "      <td>4.203206</td>\n",
       "      <td>6.815847</td>\n",
       "      <td>6.655899</td>\n",
       "      <td>8.295816</td>\n",
       "      <td>3.556779</td>\n",
       "      <td>5.794679</td>\n",
       "      <td>3.260723</td>\n",
       "      <td>5.463808</td>\n",
       "      <td>9.745537e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.393457</td>\n",
       "      <td>0.094127</td>\n",
       "      <td>3.208929</td>\n",
       "      <td>0.497443</td>\n",
       "      <td>4.318127</td>\n",
       "      <td>4.999247</td>\n",
       "      <td>9.470238</td>\n",
       "      <td>3.061990</td>\n",
       "      <td>7.312995</td>\n",
       "      <td>5.475240</td>\n",
       "      <td>1.129200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.093724</td>\n",
       "      <td>3.905293</td>\n",
       "      <td>4.858562</td>\n",
       "      <td>4.465484</td>\n",
       "      <td>0.947091</td>\n",
       "      <td>9.410307</td>\n",
       "      <td>8.137329</td>\n",
       "      <td>9.043838</td>\n",
       "      <td>9.128607</td>\n",
       "      <td>0.790795</td>\n",
       "      <td>3.105448e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2.936450</td>\n",
       "      <td>2.094812</td>\n",
       "      <td>9.493814</td>\n",
       "      <td>3.411240</td>\n",
       "      <td>4.350940</td>\n",
       "      <td>0.386062</td>\n",
       "      <td>1.303290</td>\n",
       "      <td>2.699563</td>\n",
       "      <td>7.622569</td>\n",
       "      <td>3.037162</td>\n",
       "      <td>6.599726e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>4.915597</td>\n",
       "      <td>1.953974</td>\n",
       "      <td>7.312552</td>\n",
       "      <td>9.331203</td>\n",
       "      <td>1.329366</td>\n",
       "      <td>8.286760</td>\n",
       "      <td>5.233018</td>\n",
       "      <td>7.476923</td>\n",
       "      <td>7.043560</td>\n",
       "      <td>5.745565</td>\n",
       "      <td>8.176250e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>6.772096</td>\n",
       "      <td>6.406489</td>\n",
       "      <td>4.638352</td>\n",
       "      <td>7.042340</td>\n",
       "      <td>0.912338</td>\n",
       "      <td>7.568296</td>\n",
       "      <td>1.194928</td>\n",
       "      <td>2.592840</td>\n",
       "      <td>9.386478</td>\n",
       "      <td>4.147710</td>\n",
       "      <td>2.144147e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3.940339</td>\n",
       "      <td>4.330498</td>\n",
       "      <td>6.693371</td>\n",
       "      <td>9.169265</td>\n",
       "      <td>0.858846</td>\n",
       "      <td>0.601942</td>\n",
       "      <td>2.635455</td>\n",
       "      <td>2.037859</td>\n",
       "      <td>7.883720</td>\n",
       "      <td>8.525164</td>\n",
       "      <td>4.028735e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>8.636129</td>\n",
       "      <td>1.272939</td>\n",
       "      <td>4.339175</td>\n",
       "      <td>4.417427</td>\n",
       "      <td>5.697190</td>\n",
       "      <td>8.944253</td>\n",
       "      <td>7.952686</td>\n",
       "      <td>4.917967</td>\n",
       "      <td>9.543772</td>\n",
       "      <td>5.673870</td>\n",
       "      <td>1.257168e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0    1.454481  4.940543  7.116015  3.805131  4.105432  1.832290  5.211909   \n",
       "1    4.907182  1.653654  7.339445  9.065282  7.169233  2.354136  2.893005   \n",
       "2    1.842804  1.183878  4.203206  6.815847  6.655899  8.295816  3.556779   \n",
       "3    2.393457  0.094127  3.208929  0.497443  4.318127  4.999247  9.470238   \n",
       "4    5.093724  3.905293  4.858562  4.465484  0.947091  9.410307  8.137329   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "195  2.936450  2.094812  9.493814  3.411240  4.350940  0.386062  1.303290   \n",
       "196  4.915597  1.953974  7.312552  9.331203  1.329366  8.286760  5.233018   \n",
       "197  6.772096  6.406489  4.638352  7.042340  0.912338  7.568296  1.194928   \n",
       "198  3.940339  4.330498  6.693371  9.169265  0.858846  0.601942  2.635455   \n",
       "199  8.636129  1.272939  4.339175  4.417427  5.697190  8.944253  7.952686   \n",
       "\n",
       "           x8        x9       x10             y  \n",
       "0    5.088293  3.841250  6.121133  6.575066e+06  \n",
       "1    8.720131  8.646473  3.806860  8.419881e+06  \n",
       "2    5.794679  3.260723  5.463808  9.745537e+04  \n",
       "3    3.061990  7.312995  5.475240  1.129200e+04  \n",
       "4    9.043838  9.128607  0.790795  3.105448e+05  \n",
       "..        ...       ...       ...           ...  \n",
       "195  2.699563  7.622569  3.037162  6.599726e+07  \n",
       "196  7.476923  7.043560  5.745565  8.176250e+06  \n",
       "197  2.592840  9.386478  4.147710  2.144147e+05  \n",
       "198  2.037859  7.883720  8.525164  4.028735e+06  \n",
       "199  4.917967  9.543772  5.673870  1.257168e+05  \n",
       "\n",
       "[200 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hgH-WcQ72EpF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.45448096, 4.94054287, 7.11601489, ..., 5.08829321, 3.84125023,\n",
       "        6.12113346],\n",
       "       [4.90718225, 1.65365381, 7.33944456, ..., 8.72013079, 8.64647279,\n",
       "        3.80685964],\n",
       "       [1.84280389, 1.18387834, 4.20320584, ..., 5.79467869, 3.26072251,\n",
       "        5.46380776],\n",
       "       ...,\n",
       "       [6.77209621, 6.40648915, 4.6383525 , ..., 2.59284   , 9.38647814,\n",
       "        4.14770963],\n",
       "       [3.94033913, 4.3304978 , 6.69337057, ..., 2.03785905, 7.88372005,\n",
       "        8.52516391],\n",
       "       [8.63612874, 1.27293914, 4.33917484, ..., 4.91796749, 9.54377194,\n",
       "        5.67386964]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['y']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xGhkrtkizsLL"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['y']).values\n",
    "y = df.y.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "LGYmY2_v10Kx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9SM7Oxw2gSH"
   },
   "source": [
    "  * Split the dataset into training and validation sets (80% training, 20% validation). When splitting, set random_state=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vJQuflfp2fny"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dm9etu2l3SHr"
   },
   "source": [
    "### 2. Linear Regression **[0.5]**\n",
    "\n",
    "  * Standardize the data using StandardScaler from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7yXBVXm3c12",
    "outputId": "13db9d3c-1d71-444e-fdee-461ad31c22da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3003838 ,  1.09240598, -1.10715222, ...,  0.17730494,\n",
       "         0.29239242, -0.10062555],\n",
       "       [-0.65136938, -1.05979053, -0.3780466 , ...,  1.43349113,\n",
       "        -0.35954867, -0.38347151],\n",
       "       [ 0.63491406, -1.78554978,  0.45750412, ...,  0.01295335,\n",
       "        -1.27398115,  0.07054911],\n",
       "       ...,\n",
       "       [ 1.7833874 ,  1.31178965,  0.79657848, ..., -0.10949835,\n",
       "         0.83961754, -0.74776912],\n",
       "       [ 0.93207799, -0.76735554, -0.92633629, ..., -0.43743407,\n",
       "         1.14550533,  0.50510919],\n",
       "       [-0.73214424, -1.11212895,  1.74018506, ..., -0.14082142,\n",
       "         1.21944727,  1.3074281 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "Xs_train = scaler.fit_transform(X_train)\n",
    "Xs_val = scaler.transform(X_val)\n",
    "Xs_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzTG7n684jXr"
   },
   "source": [
    "  * Use the `sklearn.linear_model.LinearRegression` function to perform linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W7QBKniH4nNR",
    "outputId": "9a526a14-7f22-4271-c9a3-0a9d718e8e12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5190965814802768"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression().fit(Xs_train, y_train)\n",
    "#reg.coef_\n",
    "reg.score(Xs_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuZVkxLP6fTM"
   },
   "source": [
    "  * Print the RMSE for training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lNOuuI866Yk9"
   },
   "outputs": [],
   "source": [
    "# function defined to calculate rmse\n",
    "def rmse(yPred, y):\n",
    "    return np.sqrt(mean_squared_error(yPred, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNo7uEUf6WBP",
    "outputId": "142ea200-e2d6-4318-c39e-93ef607c0e2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training data: 16296980.655667374\n",
      "RMSE for validation data: 14061578.864980102\n"
     ]
    }
   ],
   "source": [
    "yp_train = reg.predict(Xs_train)\n",
    "yp_val = reg.predict(Xs_val)\n",
    "print('RMSE for training data:', rmse(yp_train,y_train))\n",
    "print('RMSE for validation data:', rmse(yp_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_vTHLaW6Rgi"
   },
   "source": [
    "3. Linear Regression with Additional Features **[0.5]**\n",
    "  * Let's add more features to our dataset (degree 8) using `sklearn.preprocessing.PolynomialFeatures` You'll want to create the additional features first, then perform standardization (start from non-standardized data).\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUeMlveD9B7r",
    "outputId": "8aa5a8cb-f279-4d89-acb2-6b805894b049"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 43758)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(8)\n",
    "# start from non-standardized data\n",
    "X_poly_train = poly.fit_transform(X_train)\n",
    "X_poly_val = poly.transform(X_val)\n",
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "Xs_poly_train = scaler.fit_transform(X_poly_train)\n",
    "Xs_poly_val = scaler.transform(X_poly_val)\n",
    "Xs_poly_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLpRsAGj6bDC"
   },
   "source": [
    "* Again, use `sklearn.linear_model.LinearRegression` to perform linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ncPx-aAX9oyR",
    "outputId": "47e508c1-7fd3-4c24-b1f2-1da010935f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# apply linear regression\n",
    "reg_poly_st = LinearRegression().fit(Xs_poly_train, y_train)\n",
    "print(reg_poly_st.score(Xs_poly_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_C6oGEo1-e1D"
   },
   "source": [
    "* Print the RMSE for training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5db3a8SY-Cc-",
    "outputId": "477ac4bd-5adf-4280-d720-e9fc787b7153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Report RMSE ------\n",
      "RMSE for training data: 2.3663448165888318e-07\n",
      "RMSE for training data: 10912736.457461182\n"
     ]
    }
   ],
   "source": [
    "yps_poly_train = reg_poly_st.predict(Xs_poly_train)\n",
    "yps_poly_val = reg_poly_st.predict(Xs_poly_val)\n",
    "print('----- Report RMSE ------')\n",
    "print('RMSE for training data:', rmse(yps_poly_train,y_train))\n",
    "print('RMSE for validation data:', rmse(yps_poly_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqMXHBWD_OCC"
   },
   "source": [
    "4. Linear Regression with Additional Features and Regularization **[0.5]**\n",
    "  * Let's switch models, and instead use the `sklearn.linear_model.Ridge` function [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) to perform linear regression with regularization. Apply the model to the processed data (additional, standardized) you used in 3 above. Use a `FOR` loop to run `sklearn.linear_model.Ridge` with different `alpha` values. Specifically, sweep `alpha` from 1E-2 to 1E10 (each step is an order of magnitude jump)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "13BuCenW_O9s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.01\n",
      "RMSE for training data: 321.0124089657283\n",
      "RMSE for validation data: 10919504.125894751\n",
      "----------------\n",
      "alpha: 0.1\n",
      "RMSE for training data: 3199.349646904824\n",
      "RMSE for validation data: 10916171.329033157\n",
      "----------------\n",
      "alpha: 1\n",
      "RMSE for training data: 30988.51834150589\n",
      "RMSE for validation data: 10884651.018828351\n",
      "----------------\n",
      "alpha: 10\n",
      "RMSE for training data: 248080.36964934872\n",
      "RMSE for validation data: 10659707.103879165\n",
      "----------------\n",
      "alpha: 100\n",
      "RMSE for training data: 1196923.6228686057\n",
      "RMSE for validation data: 9484394.220119663\n",
      "----------------\n",
      "alpha: 1000\n",
      "RMSE for training data: 3609078.2596920743\n",
      "RMSE for validation data: 5633182.875138328\n",
      "----------------\n",
      "alpha: 10000\n",
      "RMSE for training data: 7712389.432217537\n",
      "RMSE for validation data: 4521905.5835024\n",
      "----------------\n",
      "alpha: 100000\n",
      "RMSE for training data: 14600498.52034878\n",
      "RMSE for validation data: 10502863.775565725\n",
      "----------------\n",
      "alpha: 1000000\n",
      "RMSE for training data: 20036025.005990032\n",
      "RMSE for validation data: 16057627.104454402\n",
      "----------------\n",
      "alpha: 10000000\n",
      "RMSE for training data: 22910819.32474683\n",
      "RMSE for validation data: 18700005.544786207\n",
      "----------------\n",
      "alpha: 100000000\n",
      "RMSE for training data: 23435716.156519353\n",
      "RMSE for validation data: 19178033.464494962\n",
      "----------------\n",
      "alpha: 1000000000\n",
      "RMSE for training data: 23494007.189870406\n",
      "RMSE for validation data: 19231116.414978746\n",
      "----------------\n",
      "alpha: 10000000000\n",
      "RMSE for training data: 23499904.341360077\n",
      "RMSE for validation data: 19236486.536391094\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(-2,11):\n",
    "    al = 10**i\n",
    "    print('alpha:',al)\n",
    "    clf = Ridge(alpha=al)\n",
    "    clf.fit(Xs_poly_train, y_train)\n",
    "    y_clf_train = clf.predict(Xs_poly_train)\n",
    "    y_clf_val = clf.predict(Xs_poly_val)\n",
    "    print('RMSE for training data:', rmse(y_clf_train,y_train))\n",
    "    print('RMSE for validation data:',rmse(y_clf_val,y_val))\n",
    "    print('----------------')\n",
    "# clf = Ridge(alpha=1.0)\n",
    "# clf.fit(Xs_poly_train, y_train)\n",
    "# print(clf.score(Xs_poly_train, y_train))\n",
    "# print(clf.score(Xs_poly_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
